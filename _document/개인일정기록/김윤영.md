> <h2>2020/11/21</h2>

- AWS SageMaker 쓰기로 결정

  SageMaker는 쉽고 빠르게 구성, 학습하고 기계 학습 모델을 배포할 수 있도록 해주는 관리형 서비스!

  Serverless로 구성하기 위해서는 SageMaker에서 EndPoint를 만들어준 다음 이 EndPoint를 람다와 연결해주어야 함

- 궁금한 점

  S3에 있는 마스크 이미지들을 SageMaker의 Notebook Instance에서 가져와서 사용하는 방법?

  S3로 SageMaker 엔드포인트를 만들 수 있나? -> S3에 모델을 저장하고, 엔드포인트는 엔드포인트 따로 만드는 듯
  
  

> <h2>2020/11/23</h2>

- AWS RDS 쓰기로 결정

  DynamoDB 쓸까도 했지만 db를 이용하는 경우는 관리자 앱, 웹 뿐이므로 속도가 크게 문제될 것 같지 않음

- 테이블 구조

  ```
  mysql> CREATE TABLE history (
      -> `id` int(11) NOT NULL AUTO_INCREMENT,
      -> `ispass` TINYINT(1) NOT NULL,
      -> `visited` DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,
      -> PRIMARY KEY(id)
      -> );
  Query OK, 0 rows affected, 2 warnings (0.21 sec)
  mysql> set time_zone='Asia/Seoul';
  ```

  통과되었는지 안 되었는지(ispass), 방문한 시간(visited)

  -> 통과 안되다가 통과한 것을 어떻게 처리할 것인지 생각해보기 -> 그냥 누적되도록 결정!

  

> <h2>2020/11/24</h2>

- AWS IoT Greengrass를 쓰자

  HTTP 통신도 가능하지만 빠른 데이터 처리를 위해 더 좋은 방법

  AI 모델을 로컬 디바이스 내에서 바로 사용 가능 (클라우드와 연결이 끊어져도 사용 가능)

  - 구현 순서

    1. 라즈베리파이에 Greengrass 그룹 배포 (설치 및 환경 구축)

    2. 이미지 분류 모델 구축(SageMaker)
    3. 사진 찍어서 모델로 예측하는 람다 함수 생성 후 Greengrass 그룹의 람다로 추가
    4. Greengrass 그룹에 머신러닝 리소스 생성 (모델 선택해서)
    5. AWS IoT Greengrass Image Classification 커넥터 생성 (람다 함수가 모델에 접근 가능해짐)
    6. 캡쳐할 이미지를 저장할 로컬 디렉터리 구성(AWS, 라즈베리파이 둘 다)
    7. [테스트]를 사용해서 구독 구성. 이벤트 트리거는 여러 가지가 있음. response topic을 subscribe하고, request topic을 publish

- 궁금한 점

  SageMaker로 만든 모델을 쓰려면 같은 계정이어야 한다. S3에 올려서 사용하면 다른 계정이어도 가능하긴 할 것 같은데 맞나?

  사람이 카메라 앞으로 왔을 때 몇 초 간격으로 request할 수 있는지 물어보고 찾아보기



> <h2>2020/11/25</h2>

- Python boto3 라이브러리로 S3에 접근할 수 있도록 IAM 사용자 권한 설정

  AmazonS3FullAccess 권한

- 기획안 발표 PPT 작성  




> <h2>2020/11/26</h2>

- 기획안 발표날

- 클라우드반 AWS 계정을 받기 전 사용할 스펙?에 대해 조사하다가 클라우드 S3에 모델을 올리지 말라는 말을 들었다. 뭐 어떡하라는 거죠?"??????? 

- 테스트용으로 API Gateway로 GET 요청 보내는 리액트 웹 만들어서  

  Lambda 함수 호출로 경보 만들고 Cloudwatch 테스트해봄

![이미지 7](https://user-images.githubusercontent.com/30336831/100345055-19d14380-3025-11eb-9f75-4b1d1388a098.png)

이렇게 나온다







